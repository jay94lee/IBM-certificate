# 1. Install and Import Dependencies 

# terminal
# pip install torch==2.0.1+cu117 torchvision==0.15.2+cu117
# aws s3 cp --profile aip-ai-expert s3://expert-user3/yolov5l.pt .  #dependency manual download 
# https://github.samsungds.net/aip-ai-expert/user3.git #ds git hub clone(yolov5) 
# pip install -r /home/jovyan/yolov5/requirements.txt #requirement install


import torch
from matplotlib import pyplot as plt
import numpy as np
import cv2



# 2. Load Model

cd yolov5

# Normal torch.hub method can't be used because of no internet connection
# model = torch.hub.load('.', 'custom', '/home/jovyan/yolov5/yolov5s.pt', source='local')
# Or you can use code bellow
from  hubconf import custom
model = custom(path='/home/jovyan/yolov5/yolov5l.pt')



# 3. Make Detections with Images

cd

# add image locally
img = '123452102.jpg'

#checking model default setting 
results = model(img)

%matplotlib inline
plt.imshow(np.squeeze(results.render()))
plt.show()
# We can see that model can't detect fire in the image




# 4. Train with custom data

import os
import cv2
import torch
import numpy as np
import pandas as pd
import shutil as sh
import matplotlib.pyplot as plt

# check for numder of data
len(os.listdir(os.path.join('/home/jovyan/fire/train', 'labels')))
len(os.listdir(os.path.join('/home/jovyan/fire/val', 'labels')))
len(os.listdir(os.path.join('/home/jovyan/fire/test', 'labels')))



# making fireconfig.yaml
with open('/home/jovyan/yolov5/fireconfig.yaml', 'w+') as f:
    f.write('path: /home/jovyan/fire\n')
    f.write('train: train/images\n')
    f.write('val: val/images\n')
    f.write('test: test/images\n\n')
    f.write('names:\n')
    f.write('  0: fire')


# checking for the GPU connection
import torch
torch.__version__

import torch
torch.cuda.is_available()


%cd '/home/jovyan/yolov5'

# finetuning with custom data
# currently using GPU, NVIDIA A100 80GB PCIe MIG 1g.10gb, 9728MiB, total 10gb
!python train.py --img 640 --batch 12  --epochs 20 --data fireconfig.yaml --weights yolov5l.pt  --exist-ok 


os.listdir(os.path.join('/home/jovyan/yolov5', 'runs', 'train'))

# change weight with best training data
from  hubconf import custom
model = custom(path='/home/jovyan/yolov5/runs/train/exp/weights/best.pt')


cd

results = model(img)
results.print()


%matplotlib inline
plt.imshow(np.squeeze(results.render()))
plt.show()
# Only custom class 'fire' detected


# in 'result.csv' and 'result.png', we can see the model precision and recall
# few images corrupted. non-normalized or out of bounds coordinates -> must ne labeled again
# precision 




모델 : Yolov5

데이터 : https://github.com/spacewalk01/yolov5-fire-detection.git
아래 kaggle dataset yolo 형식으로 변형한 dataset
https://www.kaggle.com/dataclusterlabs/fire-and-smoke-dataset
https://www.kaggle.com/atulyakumar98/fire-and-gun-dataset

Resource : CPU(4.0), Memory(16.0Gi), GPU( NVIDIA A100 80GB PCIe MIG 1g.10gb)     

Code
...

위의 fire dataset 이용 yolov5l 에 finetuning하여 이미지에서 화재를 감지할 수 있도록 test 하였습니다. 
GPU의 제한으로 인해 yolov5l로는 batch 12정도가 최대 설정 가능한 크기였습니다.
epoch 50으로 학습한 경우 precision:0.57, recall:0.52 

현업 Data : CCTV 권한 획득하여 현재 데이터 수집 가능합니다. 송전탑 가리키는 영상의 경우 1080p 입니다. 
1달 이내의 데이터만 저장되어 있어 이상데이터를 수집하는데 어려움이 있습니다. 
이상데이터는 test code와 비슷하게 퍼블릭데이터 수집하여 학습시키고, CCTV데이터는 각 사물 detection 하는 방향으로 학습 시키는 것 고려중입니다. 
test 시에 CCTV사진에 임의로 물체 합성하는 방식도 생각하였으나 실질적인 의미는 적을 것으로 보입니다. 
혹은 임의로 영상에 이상 현상 모의하여 test 하는 방식도 가능할 것으로 보입니다. 


Code
GPU 추가 배정이 있기 전까지는 제한된 resource 내에서 진행해야하는데,
모델의 크기(s,m,l) 및 batch, epoch등을 적절하게 설정하는 방법
화재의 경우 특히 빛 반사 등을 불꽃으로 판단하는 경우가 있는데, 이런 오류는 어떻게 잡을 수 있는지
열화상 데이터 수집에서 이벤트 보내고 있는게 있는데, 작업 하는 경우 등에 사람의 체온을 감지하여 알람을 보내고 있는 듯 함.
이 데이터에서 사람을 detection 하여 작업자의 체온이 높은 경우는 제외할 수 있도록 하는건?


추가 문의사항 : 
- frame anomaly detection처럼 frame단위로 이상 데이터를 잡아내는 방법
- 영상 object detection, custom labeling 후 test, 이상 데이터 학습, 이상 데이터 detection


- 배터리룸 연기 감지 
연기 데이터 : 
https://github.com/gaiasd/DFireDataset
https://drive.google.com/drive/folders/1DWgsQLVgkkLM8m-VcugHNpD5WYDbjYp5?usp=sharing
https://drive.google.com/drive/folders/1Np_FC3MuuFJgV-z0FmZwS9YzsTKdyRGJ?usp=sharing


with open('/home/jovyan/yolov5/smokefireconfig.yaml', 'w+') as f:
    f.write('path: /home/jovyan/D-Fire\n')
    f.write('train: train/images\n')
    f.write('val: val/images\n')
    f.write('names:\n')
    f.write('  0: smoke\n')
    f.write('  1: fire\n')


!python train.py --img 640 --batch 16  --epochs 20 --data smokefireconfig.yaml --weights yolov5m.pt


from  hubconf import custom
model = custom(path='/home/jovyan/yolov5/runs/train/exp3/weights/best.pt')


results = model('/home/jovyan/battery_rack_2.JPG')
results.print()

%matplotlib inline
plt.imshow(np.squeeze(results.render()))
plt.show()

!python /home/jovyan/yolov5/detect.py --source /home/jovyan/fire_smoke.mp4 --weights /home/jovyan/yolov5/runs/train/exp3/weights/best.pt



안녕하세요. 이정아입니다. 

지난 미팅 후 프로젝트 진행 사항에 대해서 먼저 말씀드리겠습니다. 

퍼블릭데이터는 이전에 말씀드린대로 약 1.7만장의 화재+연기 및 아무것도 없는 상태가 포함된 세트를 사용하였습니다. 

[case1]
1. 전기실 CCTV 이용하여 약 1200장의 데이터 확보하였습니다. CCTV 상태 및 전기실 환경에 따라 다소 뿌연 구역, 어두운 구역 등이 존재합니다. 

2. 전기실 데이터가 부족한 것을 감안하여 data augmentation, 랜덤으로 50%의 이미지에 대해 각각 좌우반전/잘라내기/밝기조정 으로 다른 이미지를 만들었습니다. 

3. 연기이미지를 합성하여 이상 데이터를 만들었습니다. 이 또한 랜덤으로 여러장의 이미지에서 하나를 선택해, 크기/반전/각도/투명도 등을 랜덤으로 정해 변환후에 합성하였습니다. 

4. 학습의 경제성을 위하여 퍼블릭데이터로 학습시킨 모델 위에 해당 데이터로 재학습 시켰습니다만, 후자의 데이터가 워낙 적어서인지 overfitting 현상 확인하였습니다. 

-> 여기까지는 CCTV 이미지에 연기 랜덤 합성하여 기존 학습한 모델에 재학습시킨 경우입니다. overfitting 현상 방지하고자 가능한 data augmentation 과정 및 인공 데이터 생성 과정에서 랜덤성을 부여하였으나, 크게 효과는 없었습니다. 


[case2]
1. 퍼블릭데이터의 경우, 대부분이 이미 연기가 커진 상태이기 때문에 모델이 연기의 초기 발생을 학습하는데 어려움을 겪었습니다. 따라서 배터리 테스트 영상에서 연기의 초기 발생 부분을 직접 라벨링하여 모델에 학습 데이터로 활용하였습니다. 

2. 데이터를 모두 종합하여 한번에 학습시켰습니다. 위에서는 학습의 경제성 및 효율성을 위하여 기존에 퍼블릭데이터를 학습시킨 모델에, 재차 인공데이터를 학습시켰습니다. overfitting 개선하고자 이번에는 퍼블릭데이터와 인공 데이터, 그리고 배터리 테스트 영상을 추가하여 한번에 학습시켰습니다. 학습에 사용하지 않았던 데이터에 대해서도 어느정도 판단이 가능한 것으로 보아 과적합 현상이 해결한 것으로 보입니다. 

3. Yolov5 모델: yolov5m, yolov5l -> yolov5m6 모델을 적용하여 현재 학습 중에 있습니다. 추가로 사용한 CCTV 이미지의 해상도가 1280정도여서 바꿔서 적용해보고 있습니다. 

-> 여전히 연기가 미세하게 퍼진 상황에서의 구분은 어려운 편입니다. 민감하게 반응하도록 하면, 영상의 뿌연 부분(이물질, 빛번짐 등으로 인한 현상)을 모두 연기로 인식하고, 이를 정상으로 학습시키면 퍼진 연기에 대해서는 전혀 인식을 못하는 상황입니다. 



※문의사항 : 

1. 지금까지 영상 데이터를 학습시키거나 혹은 test를 해도 각 프레임별로 나눠 각 이미지를 보고 판단하는 것으로 알고 있습니다. 
단순하게 그 순간만 보는 것이 아닌, 몇 프레임 이전을 같이 보고 변화를 확인하는 방법이 있을까요? 만약 이 영상이 기존에는 뿌옇지 않았는데, 어느 순간 그 형태가 변한다던가를 인지하고, 이를 활용할 수 있는 방법이 있다면 도움이 될 것 같습니다. 

2. 모델 성능을 높이는 방법
현재 학습 과정에서도 성능이 P:0.78, R: 0.75, mAP50: 0.8 정도가 나오는 상태입니다.
모델 성능을 높이기 위해 다른 모델과 Ensembling을 하거나 혹은 모델 loss를 조정하거나 이런식의 방법을 사용해보신 적이 있으신가요?
일반적으로 yolo성능을 높이기 위해 어떤 방법을 사용하시는 지 여쭙고 싶습니다. 

3. data agumentation 의 여부
augmentation 과정이 필요할까요? 해당 과정 없이 연기 합성만 하는 경우, 퍼블릭데이터 포함 약 2만장 정도 될 것 같습니다. 이중 실제 CCTV 데이터는 3000장 정도입니다. 
yolov5 doc을 보니 아래와 같은 설명이 있었습니다. 
YOLOv5 does online augmentation during training, so we do not recommend applying any augmentation steps in Roboflow for training with YOLOv5. But we recommend applying the following preprocessing steps:
Auto-Orient - to strip EXIF orientation from your images.
Resize (Stretch) - to the square input size of your model (640x640 is the YOLOv5 default).
yolo자체적으로 이미 하고 있으니, 따로 하지 않는 것을 추천하며, 만약 한다면 위의 두개에 대해서만 행한다는 말이 있었습니다. 참고로 사내에서는 Roboflow에 데이터 올리는 것이 불가능합니다. 
data aug 과정은 연기 이미지 랜덤 학습 전에 시행했었습니다. 
이 과정이 의미가 있을지, 그리고 이미지를 640x640로 바꾸는 것을 하면 좋을 지 문의드립니다. 



일단 NDA가 거의 완료된 것으로 보입니다. 
CCTV 데이터 자체를 메일로 보내는 것은 조금 어려울 수도 있어서, 만약 필요하다면 knox meeting 이라는 사내 zoom 과 같은 시스템에서 화면을 공유하는 방식을 생각중입니다. 
혹시 위 관련으로 데이터가 필요하신 부분이 있다면 말씀 부탁드립니다. 

긴 메일 읽어주셔서 감사합니다. 
좋은 주말 되십시오. 
